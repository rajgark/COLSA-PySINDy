{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e5fac55",
   "metadata": {},
   "source": [
    "# PySINDy Exploration & Applications\n",
    "\n",
    "## COLSA Corporation \n",
    "\n",
    "### Raj Garkhedkar, DACS Lab Summer 2021 Intern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1d7543",
   "metadata": {},
   "source": [
    "## Waves\n",
    "\n",
    "\n",
    "-- -- -- -- -- --\n",
    "###### Links \n",
    "\n",
    "[Convection Diffusion Equation ](https://www.sciencedirect.com/topics/physics-and-astronomy/convection-diffusion-equation)\n",
    "\n",
    "[Nonlinear Advection Diffusion Equation 2nd Order FD Scheme](https://math.mit.edu/classes/18.086/2014/reports/ZachCordero.pdf)\n",
    "\n",
    "[All Analytic Sol's Convection Diffusion](https://www.nature.com/articles/s41598-020-63982-w)\n",
    "\n",
    "[Reflected Sound Discriminator](https://github.com/diabelmehdi/Machine_Learning_project/blob/master/realiz/Documentation/machine%20learning%20report_DIAB_ELMEHDI.pdf)\n",
    "\n",
    "[Deep Learning Machine Solves the Cocktail Party Problem](https://www.technologyreview.com/2015/04/29/168316/deep-learning-machine-solves-the-cocktail-party-problem/)\n",
    "\n",
    "[Deep Karaoke: Extracting Vocals](https://arxiv.org/abs/1504.04658)\n",
    "\n",
    "[Diff Eq's in Physics](https://olewitthansen.dk/Physics/differential_equations_of_physics.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86f8770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.colors as colors\n",
    "import ipywidgets\n",
    "import itertools\n",
    "import scipy.io as sio\n",
    "import PDE_FIND as pdefind\n",
    "import pandas as pd\n",
    "import sys\n",
    "import gdown\n",
    "import tensorflow as tf\n",
    "from matplotlib.colors import LightSource\n",
    "from matplotlib import interactive, rc\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "# from IPython.display import HTML\n",
    "# plt.rcParams[\"animation.html\"] = \"jshtml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d66744",
   "metadata": {},
   "source": [
    "## Advection - Diffusion PDE\n",
    "-- -- --\n",
    "The equation: \n",
    "$$u_t + a u_x = \\epsilon u_{xx}$$\n",
    "\n",
    "This might be the density or concentration of some substance and how the energy, particles, or some other physical quantity is transferred in a physical system through two processes: _diffusion and advection_. The subscripts denote partial differentiation; e.g. $u_t$ is the partial derivative of $u$ with respect to $t$. The coefficients $a$ and $\\epsilon$ are constants that determine the strength of the advective and diffusive effects. We wish to find $u(x,t)$. Depending on context, the same equation can be called the advection–diffusion equation, drift–diffusion equation, or scalar transport equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7cf84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "2*np.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8844baa",
   "metadata": {},
   "source": [
    "### Exact Solution by Fourier Analysis\n",
    "\n",
    "Solved on a periodic domain $[-\\pi,\\pi]$, with some initial data: $$u(x,0) = u_0(x)$$\n",
    "\n",
    "Under the assumption that the solution is composed of a single Fourier mode with wavenumber $\\xi$ and time-dependent amplitude $\\hat{u}$:\n",
    "$$u(x,t; \\xi) = \\hat{u}(t) e^{i\\xi x}$$\n",
    "\n",
    "Then a simple ordinary differential equation for $\\hat{u}$:\n",
    "$$\\hat{u}'(t; \\xi) + i\\xi a \\hat{u} = -\\xi^2 \\epsilon \\hat{u}$$\n",
    "\n",
    "The scalar ODE can be solved exactly:\n",
    "$$\\hat{u}(t; \\xi) = e^{(-i \\xi a - \\epsilon \\xi^2)t} \\hat{u}(0)$$\n",
    "\n",
    "Every solution of our advection-diffusion equation can be written as a linear combination (a superposition) of simple solutions of the form above, with different wavenumbers $\\xi$. The general solution can be obtained by first, taking a Fourier transform of the initial data:\n",
    "$$\\hat{u}(t=0;\\xi) = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^\\infty u_0(x) e^{-i\\xi x}dx$$\n",
    "\n",
    "Then each mode evolves according to the solution of the ODE above:\n",
    "$$\\hat{u}'(t; \\xi) = e^{(-i \\xi a - \\epsilon \\xi^2)t} \\hat{u}(0;\\xi)$$\n",
    "\n",
    "A solution is constructed again by taking the inverse Fourier transform, meaning summing up all the Fourier modes:\n",
    "$$u(x,t) = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^\\infty \\hat{u}_0(x) e^{i\\xi x}d\\xi$$\n",
    "\n",
    "Discretizing the integral with finite points in space & time below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2616f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 64                          # Number of grid points in space\n",
    "L = 2 * np.pi                   # Width of spatial domain\n",
    "x = np.arange(-m/2,m/2)*(L/m)   # Grid points \n",
    "dx = x[1]-x[0]                  # Grid spacing\n",
    "\n",
    "tmax = 8.0   # Final time\n",
    "N = 50       # # of grid points in time\n",
    "dt = tmax/N   # interval between output times\n",
    "\n",
    "xi = np.fft.fftfreq(m)*m*2*np.pi/L \n",
    "\n",
    "# Initial data\n",
    "u = np.sin(2*x)**2 * (x<-L/4)\n",
    "uhat0 = np.fft.fft(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd147b7",
   "metadata": {},
   "source": [
    "`xi = np.fft.fftfreq(m)*m*2*np.pi/L` order of numpy's FFT frequencies\n",
    "\n",
    "The functions $u, \\hat{u}$ discussed above are replaced by finite-dimensional vectors. These vectors are related through the discrete version of the Fourier transform (DFT). \n",
    "\n",
    "Initial conditions:\n",
    "\n",
    "$$u_0(x) = \\begin{cases} \\sin^2(2x) & -\\pi \\le x < -\\pi/2 \\\\ 0 & x>-\\pi/2 \\end{cases}$$\n",
    "\n",
    "`diffusion_coef` is epsilon, the diffusion coefficient\n",
    "\n",
    "`advection_coef` is the advection coefficient\n",
    "\n",
    "Similarly, change `tmax` in the above cell to increase or decrease the time boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1bfdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_coef = 0.05    # Diffusion coefficient\n",
    "advection_coef = 1       # Advection coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61acd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution list\n",
    "frames = [u.copy()]\n",
    "\n",
    "# Solution to problem\n",
    "for n in range(1,N+1):\n",
    "    t = n*dt\n",
    "    uhat = np.exp(-(1.j*xi*advection_coef + diffusion_coef*xi**2)*t) * uhat0\n",
    "    u = np.real(np.fft.ifft(uhat))\n",
    "    frames.append(u.copy())\n",
    "\n",
    "# Initialize plotting\n",
    "fig = plt.figure(figsize=(9,4)); axes = fig.add_subplot(111)\n",
    "line, = axes.plot([],[],lw=3)\n",
    "axes.set_xlim((x[0],x[-1])); axes.set_ylim((0.,1.))\n",
    "\n",
    "def plot_frame(i):\n",
    "    #fig = plt.figure()\n",
    "    #plt.plot(x,frames[i])\n",
    "    line.set_data(x,frames[i])\n",
    "    axes.set_title('t='+str(i*dt))\n",
    "    fig.canvas.draw()\n",
    "    return fig\n",
    "\n",
    "anim = animation.FuncAnimation(fig, plot_frame,\n",
    "                                   frames=len(frames),\n",
    "                                   interval=350,\n",
    "                                   repeat=False)\n",
    "\n",
    "# def ani(): \n",
    "#     animate.FuncAnimation(fig, plot_frame,\n",
    "#                                    frames=len(frames),\n",
    "#                                    interval=350,\n",
    "#                                    repeat=True)\n",
    "plt.tight_layout()\n",
    "#anim.save('/Users/rajgark/Documents/GitHub/COLSA-PySINDy/WavesData/anim.mp4')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67330c19",
   "metadata": {},
   "source": [
    "The first approximation was to take the initial data and approximate it by just the first terms in its Fourier series. The vector $\\hat{u}$ contains the first 64 Fourier modes (because 64 points are in the spatial grid vector $x$).\n",
    "\n",
    "The time evolution of the solution is exact for the initial data vector, since it uses the exact solution formula for the ODE above.\n",
    "\n",
    "### For Generality...\n",
    "This methodology can be used to solve any linear evolution PDE (including systems of PDEs, like the following scalar PDEs):\n",
    "\n",
    "$$u_t = \\sum_{j=0}^n \\alpha_j \\frac{\\partial^j u}{\\partial x^j}.$$\n",
    "Taking Fourier transform or applying our ansatz:\n",
    "$$u(x,t; \\xi) = \\hat{u}(t) e^{i\\xi x},$$\n",
    "The following linear ODE is obtained:\n",
    "$$\\hat{u}'(t) = \\left(\\sum_{j=0}^n \\alpha_j (i\\xi)^j\\right) \\hat{u}(t) = p(\\xi)\\hat{u}(t)$$\n",
    "With solution:\n",
    "$$\\hat{u}(t) = e^{p(\\xi)t}\\hat{u}(0)$$\n",
    "so that\n",
    "$$u(x,t; \\xi) = e^{i\\xi x + p(\\xi)t} \\hat{u}(0).$$\n",
    "Here $p(\\xi)$ is a polynomial with coefficients $i^j \\alpha_j$.\n",
    "\n",
    "The odd-derivative terms correspond to imaginary terms in $p(\\xi)$, which (in the exponential) lead to changes in the phase of the solution, while even-derivative terms correspond to real terms in $p(\\xi)$, which lead to changes in the amplitude of the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9346560",
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(a) for a in frames][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce86b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "framearray = np.asarray(frames)\n",
    "framearray.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657af5c6-7304-4670-b8b3-02dac74368a6",
   "metadata": {},
   "source": [
    "So there are 51 arrays with 64 discretized points of the wave per array, this forms the dataset showing the evolution of the waves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8b2e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ut,R,rhs_des = pdefind.build_linear_system(framearray, dt, dx, D=2, P=3, time_diff = 'FD', deg_x = 4, width_x = 5, width_t = 6)\n",
    "w = pdefind.TrainSTRidge(R, Ut, 10**-2, 10, normalize = 2)\n",
    "\n",
    "print(\"Candidate functions for PDE\")\n",
    "for func in ['1'] + rhs_des[1:]: print(func)\n",
    "print('-- -- -- --')\n",
    "print('Derived PDE:')\n",
    "pdefind.print_pde(w, rhs_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c74554-c7e5-45ba-b717-0a9132ff34c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dx)\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8139d06-6980-4b10-9871-a672fd302945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bb651ce",
   "metadata": {},
   "source": [
    "## PDE-FIND Implementation\n",
    "Below is the PDE-FIND replication exercise for their advection diffusion coefficient discovery method. \n",
    "A time series of length $10^6$ is generated with $x_{n+1} \\sim \\mathcal{N}(x_n, dt)$. From this we approximate the distribution function of the future potision of the trajectory and fit to a PDE. In theory, we expect $f_t = 0.5f_{xx}$. The algorithm achieves the correct PDE with parameter error $\\sim 10^{-3}$.\n",
    "\n",
    "A second time series is used to try to identify the advection diffusion equation. This time, $x_{n+1} \\sim \\mathcal{N}(x_n + c dt, dt)$. We expect the distribution function to follow $f_t = 0.5f_{xx} - c f_x$. Trying a few different sparsity promoting methods yields different results, with greedy algorithm being the only one that works.\n",
    "\n",
    "### Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d5b240",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (14,10))\n",
    "'''\n",
    "Data Generation\n",
    "'''\n",
    "length = 10**6\n",
    "dt = 0.01\n",
    "np.random.seed(0)\n",
    "pos = np.cumsum(np.sqrt(dt)*np.random.randn(length))\n",
    "\n",
    "P = {}\n",
    "M = 0\n",
    "\n",
    "m = 5\n",
    "n = 300\n",
    "\n",
    "for i in range(m):\n",
    "    P[i] = []\n",
    "    \n",
    "for i in range(len(pos)-m):\n",
    "    \n",
    "    # center\n",
    "    y = pos[i+1:i+m+1] - pos[i]\n",
    "    M = max([M, max(abs(y))])\n",
    "    \n",
    "    # add to distribution\n",
    "    for j in range(m):\n",
    "        P[j].append(y[j])\n",
    "    \n",
    "bins = np.linspace(-M,M,n+1)\n",
    "x = np.linspace(M*(1/n-1),M*(1-1/n),n)\n",
    "dx = x[2]-x[1]\n",
    "T = np.linspace(0,dt*(m-1),m)\n",
    "U = np.zeros((n,m))\n",
    "for i in range(m):\n",
    "    U[:,i] = plt.hist(P[i],bins,label=r'$t = $' + str(i*dt+dt))[0]/float(dx*(len(pos)-m))\n",
    "    \n",
    "plt.xlabel('Location')\n",
    "plt.ylabel(r'$f(x,t)$')\n",
    "plt.title(r'Histograms for $f(x,t)$')\n",
    "#xticks(fontsize = tickfontsize); yticks(fontsize = tickfontsize)\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebff550",
   "metadata": {},
   "outputs": [],
   "source": [
    "U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97c977a-cc45-4b10-9c64-4505736a13b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ut,R,rhs_des = pdefind.build_linear_system(U, dt, dx, D=4, P=5, time_diff = 'FD', deg_x = 4, width_x = 30, width_t = 1)\n",
    "w = pdefind.TrainSTRidge(R, Ut, 10**-2, 10, normalize = 2)\n",
    "\n",
    "print(\"Candidate functions for PDE\")\n",
    "for func in ['1'] + rhs_des[1:]: print(func)\n",
    "\n",
    "print(\"\\nPDE derived from data:\")\n",
    "pdefind.print_pde(w, rhs_des)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a858348f",
   "metadata": {},
   "source": [
    "### Advection - Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edc7997",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (14,10))\n",
    "''' \n",
    "Data Generation\n",
    "'''\n",
    "length = 10**6\n",
    "\n",
    "dt = 0.099    # Diffusion Term\n",
    "c = 5         # Advection Term\n",
    "np.random.seed(0)\n",
    "pos = np.cumsum(np.sqrt(dt)*np.random.randn(length)) + c*dt*np.arange(length)\n",
    "\n",
    "P = {}\n",
    "M = 0\n",
    "\n",
    "m = 5\n",
    "n = 300\n",
    "\n",
    "for i in range(m):\n",
    "    P[i] = []\n",
    "    \n",
    "for i in range(len(pos)-m):\n",
    "    \n",
    "    # center\n",
    "    y = pos[i+1:i+m+1] - pos[i]\n",
    "    M = max([M, max(abs(y))])\n",
    "    \n",
    "    # add to distribution\n",
    "    for j in range(m):\n",
    "        P[j].append(y[j])\n",
    "    \n",
    "bins = np.linspace(-M,M,n+1)\n",
    "x = np.linspace(M*(1/n-1),M*(1-1/n),n)\n",
    "dx = x[2]-x[1]\n",
    "T =  np.linspace(0,dt*(m-1),m)\n",
    "U = np.zeros((n,m))\n",
    "for i in range(m):\n",
    "    U[:,i] = plt.hist(P[i],bins,label=r'$t = $' + str(i*dt+dt))[0]/float(dx*(len(pos)-m))\n",
    "    \n",
    "    \n",
    "plt.xlabel('Location')\n",
    "plt.ylabel(r'$f(x,t)$')\n",
    "plt.title(r'Histograms for $f(x,t)$')\n",
    "#plt.xticks(fontsize = tickfontsize); yticks(fontsize = tickfontsize)\n",
    "plt.legend(loc = 'upper right', fontsize = 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f64579a-149f-44b2-a17b-1c39abb1a6ed",
   "metadata": {},
   "source": [
    "Now try to identify the dynamics. This is an example of how different sparsity promoting regression methods can behave differently. Here the STRidge algorithm works only when the data is not normalized. The greedy algorithm seems to be fairly robust to small changes, and Lasso works with some tuning (maybe only because we know the right answer). Normally STRidge with $L^2$ normalization outperforms all the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732cc446-1deb-49eb-b380-5d4f123c36d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ut,R,rhs_des = pdefind.build_linear_system(U, dt, dx, D=4, P=5, time_diff = 'FD', deg_x = 4, width_x = 30, width_t = 1)\n",
    "\n",
    "print(\"Candidate functions for PDE\")\n",
    "for func in ['1'] + rhs_des[1:]: print(func)\n",
    "print('-- -- -- -- -- -- -- --')\n",
    "print(\"\\nPDE derived with STRidge and L^2 normalization (Somewhat Correct PDE)\")\n",
    "w = pdefind.TrainSTRidge(R, Ut, 1, 4, normalize = 2)\n",
    "pdefind.print_pde(w, rhs_des)\n",
    "\n",
    "print(\"PDE derived with STRidge without normalization\")\n",
    "w = pdefind.TrainSTRidge(R, Ut, 1, 0.01, normalize = 0)\n",
    "pdefind.print_pde(w, rhs_des)\n",
    "\n",
    "print(\"PDE derived with greedy algorithm (Correct PDE!)\")\n",
    "w = pdefind.FoBaGreedy(R, Ut,10)\n",
    "pdefind.print_pde(w, rhs_des)\n",
    "\n",
    "print(\"PDE derived with LASSO algorithm\")\n",
    "w = pdefind.Lasso(R, Ut,10)\n",
    "pdefind.print_pde(w, rhs_des)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7312e873-f0ce-4fe2-a687-f7dec5011db4",
   "metadata": {},
   "source": [
    "### Reaction Diffusion System, PDE-FIND Implementation\n",
    "\n",
    "PDE-FIND for a $\\lambda - \\omega$ reaction diffusion system exhibiting sprial waves on a periodic domain. We derive PDE's for each of two quantities, having dependancies on each other; $u$ and $v$.\n",
    "\n",
    "$$\\begin{align*} u_t &= 0.1\\nabla^2 u + \\lambda(A)u - \\omega(A)v\\\\ v_t &= 0.1\\nabla^2 v + \\omega(A)u + \\lambda(A)v\\\\ A^2 &= u^2 + v^2,\\, \\omega(A) = -\\beta A^2, \\lambda(A) = 1-A^2 \\end{align*}$$\n",
    "\n",
    "Unlike other implmentations, we allow for $u_t$ to be dependent on derivatives of $v$, even though this is not the case in the true PDE. The sparse regression is still able to derive the correct PDE.\n",
    "-- -- -- -- \n",
    "##### Notes\n",
    "\n",
    "Their dataset wasn't generated, was just a MATLAB script & function. I generated data from their MATLAB code, converted it to a .csv below & carried out the rest of the notebook, dataset in the repo (as a .csv - original MATLAB scripts in it as well but they take forever to compute & the .mat file containing the data is too big for MATLAB and Jupyter to handle effectively. \n",
    "\n",
    "I can't upload the original `reacdiffdataset.mat` because the filesize is too large for GitHub and GitHub LFS requires migrating the entire working directory & a whole bunch of unnecessary stuff. \n",
    "\n",
    "_IMPORTANT_: The easiest option for reproducibility is to go to [this Google Drive link](https://drive.google.com/drive/folders/1E3esK-Ct-aAiOFacaZ9x4v_B-1OvNi7c?usp=sharing) and download the `reacdiffdataset.mat` file, change the filepath for `data` below, and carry out the rest of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f9eba09-c435-49c9-9ff2-d69e1f655390",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sio.loadmat('/Users/rajgark/Desktop/Colsa/reacdiffdataset.mat') # change filepath here\n",
    "# t = np.array(data['t'][:,0])\n",
    "# x = np.array(data['x'][0,:])\n",
    "# y = np.array(data['y'][0,:])\n",
    "# U = np.array(data['u'])\n",
    "# V = np.array(data['v'])\n",
    "\n",
    "t = data['t'][:,0]\n",
    "x = data['x'][0,:]\n",
    "y = data['y'][0,:]\n",
    "U = data['u']\n",
    "V = data['v']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a7709cf-763c-4c0a-8549-5db40f2bb1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below Code Is attempting to use gdown for downloading the large files - ignore.\n",
    "\n",
    "# tf.io.write_file(\"/Users/rajgark/Documents/GitHub/COLSA-PySINDy/WavesData/nparrays/t_tens\", tf.io.serialize_tensor(tf.convert_to_tensor(t)))\n",
    "# tf.io.write_file(\"/Users/rajgark/Documents/GitHub/COLSA-PySINDy/WavesData/nparrays/x_tens\", tf.io.serialize_tensor(tf.convert_to_tensor(x)))\n",
    "# tf.io.write_file(\"/Users/rajgark/Documents/GitHub/COLSA-PySINDy/WavesData/nparrays/y_tens\", tf.io.serialize_tensor(tf.convert_to_tensor(y)))\n",
    "# tf.io.write_file(\"/Users/rajgark/Documents/GitHub/COLSA-PySINDy/WavesData/nparrays/U_tens\", tf.io.serialize_tensor(tf.convert_to_tensor(U)))\n",
    "# tf.io.write_file(\"/Users/rajgark/Documents/GitHub/COLSA-PySINDy/WavesData/nparrays/V_tens\", tf.io.serialize_tensor(tf.convert_to_tensor(V)))\n",
    "\n",
    "# #tf.io.write_file(tf.io.serialize_tensor(tf.convert_to_tensor(t)), \"/Users/rajgark/Documents/GitHub/COLSA-PySINDy/WavesData/nparrays/t_tens\")\n",
    "# \"\"\"tf.convert_to_tensor(x, allow_pickle=False)\n",
    "# tf.convert_to_tensor(y, allow_pickle=False)\n",
    "# tf.convert_to_tensor(U, allow_pickle=False)\n",
    "# tf.convert_to_tensor(V, allow_pickle=False)\"\"\"\n",
    "\n",
    "# #gdown_url = 'https://drive.google.com/drive/folders/1E3esK-Ct-aAiOFacaZ9x4v_B-1OvNi7c?usp=sharing'\n",
    "# gdown_url = 'https://drive.google.com/drive/folders/1E3esK-Ct-aAiOFacaZ9x4v_B-1OvNi7c?usp=sharing'\n",
    "# t_url = 't_tens'\n",
    "# x_url = 'x_tens'\n",
    "# y_url = 'y_tens'\n",
    "# U_url = 'U_tens'\n",
    "# V_url = 'V_tens'\n",
    "\n",
    "# tfile = gdown.download(gdown_url, t_url, quiet=False)\n",
    "# xfile = gdown.download(gdown_url, x_url, quiet=False)\n",
    "# yfile = gdown.download(gdown_url, y_url, quiet=False)\n",
    "# ufile = gdown.download(gdown_url, U_url, quiet=False)\n",
    "# vfile = gdown.download(gdown_url, V_url, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2ccb0a9-fbb5-4d36-b1b7-3a1effc96d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t shape:  (201,)\n",
      "x shape:  (512,)\n",
      "y shape:  (512,)\n",
      "U shape:  (512, 512, 201)\n",
      "V shape:  (512, 512, 201)\n",
      "-- -- -- -- -- -- -- -- --\n",
      "t type:  <class 'numpy.ndarray'>\n",
      "x type:  <class 'numpy.ndarray'>\n",
      "y type:  <class 'numpy.ndarray'>\n",
      "U type:  <class 'numpy.ndarray'>\n",
      "V type:  <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print('t shape: ',t.shape)\n",
    "print('x shape: ',x.shape)\n",
    "print('y shape: ',y.shape)\n",
    "print('U shape: ',U.shape)\n",
    "print('V shape: ',V.shape)\n",
    "print('-- -- -- -- -- -- -- -- --')\n",
    "print('t type: ',type(t))\n",
    "print('x type: ',type(x))\n",
    "print('y type: ',type(y))\n",
    "print('U type: ',type(U))\n",
    "print('V type: ',type(V))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c28560c-6d44-4667-9451-adb26479c6f8",
   "metadata": {},
   "source": [
    "`U` and `V` tensors are massive: `(512, 512, 201)`. Ensuring everything is imported properly with appropriate variable types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d27ad59b-81e2-46ce-9ed3-c43e227e44e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be8b8ae38b8478d89212e93f768cb05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-e8f6719e0e20>:13: MatplotlibDeprecationWarning: shading='flat' when X and Y have the same dimensions as C is deprecated since 3.3.  Either specify the corners of the quadrilaterals with X and Y, or pass shading='auto', 'nearest' or 'gouraud', or set rcParams['pcolor.shading'].  This will become an error two minor releases later.\n",
      "  plt.pcolor(xx,yy, U[:,:,10], cmap='coolwarm')\n",
      "<ipython-input-7-e8f6719e0e20>:18: MatplotlibDeprecationWarning: shading='flat' when X and Y have the same dimensions as C is deprecated since 3.3.  Either specify the corners of the quadrilaterals with X and Y, or pass shading='auto', 'nearest' or 'gouraud', or set rcParams['pcolor.shading'].  This will become an error two minor releases later.\n",
      "  plt.pcolor(xx,yy, V[:,:,10], cmap='coolwarm')\n"
     ]
    }
   ],
   "source": [
    "n = len(x) # also the length of y\n",
    "steps = len(t)\n",
    "dx = x[2]-x[1]\n",
    "dy = y[2]-y[1]\n",
    "dt = t[2]-t[1]\n",
    "\n",
    "plt.figure(figsize = (12, 6))\n",
    "xx, yy = np.meshgrid(\n",
    "    np.arange(n)*dx,\n",
    "    np.arange(n)*dy)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.pcolor(xx,yy, U[:,:,10], cmap='coolwarm')\n",
    "plt.title('U', fontsize = 20)\n",
    "plt.xlabel('x', fontsize = 16)\n",
    "plt.ylabel('y', fontsize = 16)\n",
    "plt.subplot(1,2,2)\n",
    "plt.pcolor(xx,yy, V[:,:,10], cmap='coolwarm')\n",
    "plt.title('V', fontsize = 20)\n",
    "plt.xlabel('x', fontsize = 16)\n",
    "plt.ylabel('y', fontsize = 16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e796cf83-59ce-4a04-818d-a9e8a73256c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a collection of data points \n",
    "np.random.seed(0) # so that numbers in paper are reproducible\n",
    "\n",
    "num_xy = 5000 # needs to be very high to work with noise\n",
    "num_t = 30\n",
    "num_points = num_xy * num_t\n",
    "boundary = 5\n",
    "points = {}\n",
    "count = 0\n",
    "\n",
    "for p in range(num_xy):\n",
    "    x = np.random.choice(np.arange(boundary,n-boundary),1)[0]\n",
    "    y = np.random.choice(np.arange(boundary,n-boundary),1)[0]\n",
    "    for t in range(num_t):\n",
    "        points[count] = [x,y,6*t+10]\n",
    "        count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d22d9ad-cb72-4c82-82f1-7078d199f3b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "006f7e95-7449-4d0b-9e2d-ca916027ff5e",
   "metadata": {},
   "source": [
    "#### Construct $\\Theta (U)$ and compute $U_t$¶\n",
    "\n",
    "First derivatives are taken around each one of the points then combined these with a number of candidate functions of u and v for the PDE. All of the candidate funcitons are listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f8564b3-3582-44e1-a6d9-d33e01d82884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take up to second order derivatives.\n",
    "u = np.zeros((num_points,1))\n",
    "v = np.zeros((num_points,1))\n",
    "ut = np.zeros((num_points,1))\n",
    "vt = np.zeros((num_points,1))\n",
    "ux = np.zeros((num_points,1))\n",
    "uy = np.zeros((num_points,1))\n",
    "uxx = np.zeros((num_points,1))\n",
    "uxy = np.zeros((num_points,1))\n",
    "uyy = np.zeros((num_points,1))\n",
    "vx = np.zeros((num_points,1))\n",
    "vy = np.zeros((num_points,1))\n",
    "vxx = np.zeros((num_points,1))\n",
    "vxy = np.zeros((num_points,1))\n",
    "vyy = np.zeros((num_points,1))\n",
    "\n",
    "N = 2 * boundary - 1  # number of points to use in fitting\n",
    "Nt = N\n",
    "deg = 4 # degree of polynomial to use\n",
    "\n",
    "ntplus = 5 # (Nt + 1)/2\n",
    "ntminus = 4 # (Nt - 1)/2\n",
    "nt_index = int((Nt-1)/2)\n",
    "lb = int(t - (Nt - 1)/2)\n",
    "ub = int(t + (Nt + 1)/2)\n",
    "for p in points.keys():\n",
    "    \n",
    "    [x,y,t] = points[p]\n",
    "    \n",
    "    # value of function\n",
    "    u[p] = U[x,y,t]\n",
    "    v[p] = V[x,y,t]\n",
    "    \n",
    "    # time derivatives \n",
    "    ut[p] = pdefind.PolyDiffPoint(U[x,y,lb:ub], np.arange(Nt)*dt, deg, 1, index = nt_index)[0]\n",
    "    vt[p] = pdefind.PolyDiffPoint(V[x,y,lb:ub], np.arange(Nt)*dt, deg, 1, index = nt_index)[0]\n",
    "    \n",
    "    # spatial derivatives\n",
    "    ux_diff = pdefind.PolyDiffPoint(U[x-ntminus:x+ntplus,y,t], np.arange(N)*dx, deg, index = 2)\n",
    "    uy_diff = pdefind.PolyDiffPoint(U[x,y-ntminus:y+ntplus,t], np.arange(N)*dy, deg, index = 2)\n",
    "    vx_diff = pdefind.PolyDiffPoint(V[x-ntminus:x+ntplus,y,t], np.arange(N)*dx, deg, index = 2)\n",
    "    vy_diff = pdefind.PolyDiffPoint(V[x,y-ntminus:y+ntplus,t], np.arange(N)*dy, deg, index = 2)\n",
    "    ux_diff_yp = pdefind.PolyDiffPoint(U[x-ntminus:x+ntplus,y+1,t], np.arange(N)*dx, deg, index = 2)\n",
    "    ux_diff_ym = pdefind.PolyDiffPoint(U[x-ntminus:x+ntplus,y-1,t], np.arange(N)*dx, deg, index = 2)\n",
    "    vx_diff_yp = pdefind.PolyDiffPoint(V[x-ntminus:x+ntplus,y+1,t], np.arange(N)*dx, deg, index = 2)\n",
    "    vx_diff_ym = pdefind.PolyDiffPoint(V[x-ntminus:x+ntplus,y-1,t], np.arange(N)*dx, deg, index = 2)\n",
    "    \n",
    "    ux[p] = ux_diff[0]\n",
    "    uy[p] = uy_diff[0]\n",
    "    uxx[p] = ux_diff[0]\n",
    "    uxy[p] = (ux_diff_yp[0]-ux_diff_ym[0])/(2*dy)\n",
    "    uyy[p] = uy_diff[0]\n",
    "    \n",
    "    vx[p] = vx_diff[0]\n",
    "    vy[p] = vy_diff[0]\n",
    "    vxx[p] = vx_diff[0]\n",
    "    vxy[p] = (vx_diff_yp[0]-vx_diff_ym[0])/(2*dy)\n",
    "    vyy[p] = vy_diff[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0e4edcf7-f5ed-4104-b988-5aeba375ed46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " 'u_{x}',\n",
       " 'u_{y}',\n",
       " 'u_{xx}',\n",
       " 'u_{xy}',\n",
       " 'u_{yy}',\n",
       " 'v_{x}',\n",
       " 'v_{y}',\n",
       " 'v_{xx}',\n",
       " 'v_{xy}',\n",
       " 'v_{yy}',\n",
       " 'v',\n",
       " 'u',\n",
       " 'v^2',\n",
       " 'uv',\n",
       " 'u^2',\n",
       " 'v^3',\n",
       " 'uv^2',\n",
       " 'u^2v',\n",
       " 'u^3',\n",
       " 'vu_{x}',\n",
       " 'uu_{x}',\n",
       " 'v^2u_{x}',\n",
       " 'uvu_{x}',\n",
       " 'u^2u_{x}',\n",
       " 'v^3u_{x}',\n",
       " 'uv^2u_{x}',\n",
       " 'u^2vu_{x}',\n",
       " 'u^3u_{x}',\n",
       " 'vu_{y}',\n",
       " 'uu_{y}',\n",
       " 'v^2u_{y}',\n",
       " 'uvu_{y}',\n",
       " 'u^2u_{y}',\n",
       " 'v^3u_{y}',\n",
       " 'uv^2u_{y}',\n",
       " 'u^2vu_{y}',\n",
       " 'u^3u_{y}',\n",
       " 'vu_{xx}',\n",
       " 'uu_{xx}',\n",
       " 'v^2u_{xx}',\n",
       " 'uvu_{xx}',\n",
       " 'u^2u_{xx}',\n",
       " 'v^3u_{xx}',\n",
       " 'uv^2u_{xx}',\n",
       " 'u^2vu_{xx}',\n",
       " 'u^3u_{xx}',\n",
       " 'vu_{xy}',\n",
       " 'uu_{xy}',\n",
       " 'v^2u_{xy}',\n",
       " 'uvu_{xy}',\n",
       " 'u^2u_{xy}',\n",
       " 'v^3u_{xy}',\n",
       " 'uv^2u_{xy}',\n",
       " 'u^2vu_{xy}',\n",
       " 'u^3u_{xy}',\n",
       " 'vu_{yy}',\n",
       " 'uu_{yy}',\n",
       " 'v^2u_{yy}',\n",
       " 'uvu_{yy}',\n",
       " 'u^2u_{yy}',\n",
       " 'v^3u_{yy}',\n",
       " 'uv^2u_{yy}',\n",
       " 'u^2vu_{yy}',\n",
       " 'u^3u_{yy}',\n",
       " 'vv_{x}',\n",
       " 'uv_{x}',\n",
       " 'v^2v_{x}',\n",
       " 'uvv_{x}',\n",
       " 'u^2v_{x}',\n",
       " 'v^3v_{x}',\n",
       " 'uv^2v_{x}',\n",
       " 'u^2vv_{x}',\n",
       " 'u^3v_{x}',\n",
       " 'vv_{y}',\n",
       " 'uv_{y}',\n",
       " 'v^2v_{y}',\n",
       " 'uvv_{y}',\n",
       " 'u^2v_{y}',\n",
       " 'v^3v_{y}',\n",
       " 'uv^2v_{y}',\n",
       " 'u^2vv_{y}',\n",
       " 'u^3v_{y}',\n",
       " 'vv_{xx}',\n",
       " 'uv_{xx}',\n",
       " 'v^2v_{xx}',\n",
       " 'uvv_{xx}',\n",
       " 'u^2v_{xx}',\n",
       " 'v^3v_{xx}',\n",
       " 'uv^2v_{xx}',\n",
       " 'u^2vv_{xx}',\n",
       " 'u^3v_{xx}',\n",
       " 'vv_{xy}',\n",
       " 'uv_{xy}',\n",
       " 'v^2v_{xy}',\n",
       " 'uvv_{xy}',\n",
       " 'u^2v_{xy}',\n",
       " 'v^3v_{xy}',\n",
       " 'uv^2v_{xy}',\n",
       " 'u^2vv_{xy}',\n",
       " 'u^3v_{xy}',\n",
       " 'vv_{yy}',\n",
       " 'uv_{yy}',\n",
       " 'v^2v_{yy}',\n",
       " 'uvv_{yy}',\n",
       " 'u^2v_{yy}',\n",
       " 'v^3v_{yy}',\n",
       " 'uv^2v_{yy}',\n",
       " 'u^2vv_{yy}',\n",
       " 'u^3v_{yy}']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Form a huge matrix using up to quadratic polynomials in all variables.\n",
    "X_data = np.hstack([u,v])\n",
    "X_ders = np.hstack([np.ones((num_points,1)), ux, uy, uxx, uxy, uyy, vx, vy, vxx, vxy, vyy])\n",
    "X_ders_descr = ['','u_{x}', 'u_{y}','u_{xx}','u_{xy}','u_{yy}','v_{x}', 'v_{y}','v_{xx}','v_{xy}','v_{yy}']\n",
    "X, description = pdefind.build_Theta(X_data, X_ders, X_ders_descr, 3, data_description = ['u','v'])\n",
    "['1'] + description[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8b33e7-8c78-478a-9cf3-30db06e80901",
   "metadata": {},
   "source": [
    "#### Solve for $\\xi$\n",
    "TrainSTRidge splits the data up into 80% for training and 20% for validation. It searches over various tolerances in the STRidge algorithm and finds the one with the best performance on the validation set, including an $\\ell^0$ penalty for $\\xi$ in the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b76c3f2b-6045-4e6b-a60c-5512cad245e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rajgark/Documents/GitHub/COLSA-PySINDy/Notebooks/PDE_FIND.py:430: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  w_best = np.linalg.lstsq(TrainR, TrainY)[0]\n",
      "/Users/rajgark/Documents/GitHub/COLSA-PySINDy/Notebooks/PDE_FIND.py:575: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if lam != 0: w = np.linalg.lstsq(X.T.dot(X) + lam*np.eye(d),X.T.dot(y))[0]\n",
      "/Users/rajgark/Documents/GitHub/COLSA-PySINDy/Notebooks/PDE_FIND.py:601: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if lam != 0: w[biginds] = np.linalg.lstsq(X[:, biginds].T.dot(X[:, biginds]) + lam*np.eye(len(biginds)),X[:, biginds].T.dot(y))[0]\n",
      "/Users/rajgark/Documents/GitHub/COLSA-PySINDy/Notebooks/PDE_FIND.py:605: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if biginds != []: w[biginds] = np.linalg.lstsq(X[:, biginds],y)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u_t = (-0.505711 +0.000000i)v\n",
      "    + (0.126524 +0.000000i)u\n",
      "    + (0.708195 +0.000000i)v^3\n",
      "    + (0.703735 +0.000000i)u^2v\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "c = pdefind.TrainSTRidge(X,ut,10**-5,1)\n",
    "pdefind.print_pde(c, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e591deff-c894-4ed9-8584-479ac9272438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v_t = (0.119467 +0.000000i)v\n",
      "    + (0.500336 +0.000000i)u\n",
      "    + (-0.702871 +0.000000i)uv^2\n",
      "    + (-0.706025 +0.000000i)u^3\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "c = pdefind.TrainSTRidge(X,vt,10**-5,1)\n",
    "pdefind.print_pde(c, description, ut = 'v_t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "56cb1a1b-3628-4b8c-ae6f-1212e1c466d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016714285714285976\n",
      "0.013088645959808971\n"
     ]
    }
   ],
   "source": [
    "err = abs(np.array([(0.1-0.099977)*100/0.1,  (0.1-0.100033)*100/0.1,\n",
    "                    (0.1-0.100009)*100/0.1,  (0.1-0.099971)*100/0.1,\n",
    "                    (1-0.999887)*100,        (1-1.000335)*100,\n",
    "                    (1-0.999906)*100,        (1-0.999970)*100,\n",
    "                    (1-0.999980)*100,        (1-0.999978)*100,\n",
    "                    (1-0.999976)*100,        (1-1.000353)*100,\n",
    "                    (1-0.999923)*100,        (1-1.000332)*100]))\n",
    "print(np.mean(err))\n",
    "print(np.std(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4f52c3-70db-4689-99d1-7c4b2d2490cb",
   "metadata": {},
   "source": [
    "#### Identify the dynamics using the same dataset but with artificial noise\n",
    "In all other examples, we used 1% of the standard deviation of the solution for the magnitude of the noise added. Even with using many more points, we weren't able to identify the correct dynamics with that noise level. Instead we use 0.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe604b75-880f-4cd9-bdba-3a9883444c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now try adding noise.\n",
    "np.random.seed(0)\n",
    "Un = U + 0.005*np.std(U)*np.random.randn(n,n,steps)\n",
    "Vn = V + 0.005*np.std(V)*np.random.randn(n,n,steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02149821-c478-42e1-bc4f-82beef8a8bd6",
   "metadata": {},
   "source": [
    "#### Denoise via SVD¶\n",
    "Denoise via taking SVD and truncating where singular values flatten off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e6c36826-18a7-4a90-a9d1-728d3d6fc88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denoise using POD.\n",
    "FUn = Un.reshape(n**2,steps)\n",
    "FVn = Vn.reshape(n**2,steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a25dfd62-8b3a-461f-90e5-d31ee160081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "uun,usn,uvn = np.linalg.svd(FUn, full_matrices = False)\n",
    "vun,vsn,vvn = np.linalg.svd(FVn, full_matrices = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "380536c8-8a23-46cb-9f0c-b8a9e888cff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7a918bf97514bdb97acd380df4fb170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots()\n",
    "plt.semilogy(usn)\n",
    "plt.semilogy(vsn)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a0f945-39c4-41ac-8ed0-cedba143f6eb",
   "metadata": {},
   "source": [
    "Truncating around 15 ish where the values flatten off after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "576e8b13-db79-4191-b05d-60d49b6011cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 15\n",
    "Un = (uun[:,:dim].dot(np.diag(usn[:dim]).dot(uvn[:dim,:]))).reshape(n,n,steps)\n",
    "Vn = (vun[:,:dim].dot(np.diag(vsn[:dim]).dot(vvn[:dim,:]))).reshape(n,n,steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef446220-f68d-4638-ad94-687404fab215",
   "metadata": {},
   "source": [
    "Now that we've denoised the data (atleast somewhat) we just proceed as we did for the clean data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a7b7f395-0ae8-46ff-9806-3ce634e5b07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take up to second order derivatives.\n",
    "un = np.zeros((num_points,1))\n",
    "vn = np.zeros((num_points,1))\n",
    "utn = np.zeros((num_points,1))\n",
    "vtn = np.zeros((num_points,1))\n",
    "uxn = np.zeros((num_points,1))\n",
    "uyn = np.zeros((num_points,1))\n",
    "uxxn = np.zeros((num_points,1))\n",
    "uxyn = np.zeros((num_points,1))\n",
    "uyyn = np.zeros((num_points,1))\n",
    "vxn = np.zeros((num_points,1))\n",
    "vyn = np.zeros((num_points,1))\n",
    "vxxn = np.zeros((num_points,1))\n",
    "vxyn = np.zeros((num_points,1))\n",
    "vyyn = np.zeros((num_points,1))\n",
    "\n",
    "N = 2*boundary-1  # number of points to use in fitting polynomial for spatial derivative\n",
    "Nt = N # and for time derivatives\n",
    "deg = 4 # degree of polynomial to use\n",
    "\n",
    "ntplus = 5 # (Nt + 1)/2\n",
    "ntminus = 4 # (Nt - 1)/2\n",
    "nt_index = int((Nt-1)/2)\n",
    "lb = int(t - (Nt - 1)/2)\n",
    "ub = int(t + (Nt + 1)/2)\n",
    "\n",
    "for p in points.keys():\n",
    "    \n",
    "    [x,y,t] = points[p]\n",
    "    \n",
    "    # value of function\n",
    "    un[p] = Un[x,y,t]\n",
    "    vn[p] = Vn[x,y,t]\n",
    "    \n",
    "    # time derivatives\n",
    "    utn[p] = pdefind.PolyDiffPoint(Un[x,y,lb:ub], np.arange(Nt)*dt, deg, index = 1)[0]\n",
    "    vtn[p] = pdefind.PolyDiffPoint(Vn[x,y,lb:ub], np.arange(Nt)*dt, deg, index = 1)[0]\n",
    "    \n",
    "    # spatial derivatives\n",
    "    ux_diff_n = pdefind.PolyDiffPoint(Un[x-ntminus:x+ntplus,y,t], np.arange(N)*dx, deg, index = 2)\n",
    "    uy_diff_n = pdefind.PolyDiffPoint(Un[x,y-ntminus:y+ntplus,t], np.arange(N)*dy, deg, index = 2)\n",
    "    vx_diff_n = pdefind.PolyDiffPoint(Vn[x-ntminus:x+ntplus,y,t], np.arange(N)*dx, deg, index = 2)\n",
    "    vy_diff_n = pdefind.PolyDiffPoint(Vn[x,y-ntminus:y+ntplus,t], np.arange(N)*dy, deg, index = 2)\n",
    "    ux_diff_yp_n = pdefind.PolyDiffPoint(Un[x-ntminus:x+ntplus,y+1,t], np.arange(N)*dx, deg, index = 2)\n",
    "    ux_diff_ym_n = pdefind.PolyDiffPoint(Un[x-ntminus:x+ntplus,y-1,t], np.arange(N)*dx, deg, index = 2)\n",
    "    vx_diff_yp_n = pdefind.PolyDiffPoint(Vn[x-ntminus:x+ntplus,y+1,t], np.arange(N)*dx, deg, index = 2)\n",
    "    vx_diff_ym_n = pdefind.PolyDiffPoint(Vn[x-ntminus:x+ntplus,y-1,t], np.arange(N)*dx, deg, index = 2)\n",
    "    \n",
    "    uxn[p] = ux_diff_n[0]\n",
    "    uyn[p] = uy_diff_n[0]\n",
    "    uxxn[p] = ux_diff_n[0]\n",
    "    uxyn[p] = (ux_diff_yp_n[0]-ux_diff_ym_n[0])/(2*dy)\n",
    "    uyyn[p] = uy_diff_n[0]\n",
    "    \n",
    "    vxn[p] = vx_diff_n[0]\n",
    "    vyn[p] = vy_diff_n[0]\n",
    "    vxxn[p] = vx_diff_n[0]\n",
    "    vxyn[p] = (vx_diff_yp_n[0]-vx_diff_ym_n[0])/(2*dy)\n",
    "    vyyn[p] = vy_diff_n[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3cc743ca-bf1c-4bae-b76a-5fc2436c8f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form a huge matrix using up to quadratic polynomials in all variables.\n",
    "X_data_n = np.hstack([un,vn])\n",
    "X_ders_n = np.hstack([np.ones((num_points,1)), uxn, uyn, uxxn, uxyn, uyyn, vxn, vyn, vxxn, vxyn, vyyn])\n",
    "X_ders_descr = ['','u_{x}', 'u_{y}','u_{xx}','u_{xy}','u_{yy}','v_{x}', 'v_{y}','v_{xx}','v_{xy}','v_{yy}']\n",
    "X_n, description = pdefind.build_Theta(X_data_n, X_ders_n, X_ders_descr, 3, data_description = ['u','v'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "41e5926f-cf5c-47aa-863e-45d037c627bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -0.1466456  -0.60529448 ...  0.1625734   0.30337828\n",
      "   0.69582286]\n",
      " [ 1.         -0.1173339  -0.3843511  ...  0.19503733 -0.18427085\n",
      "   0.83741303]\n",
      " [ 1.         -0.0589832  -0.14796994 ...  0.24218373 -0.18740136\n",
      "   0.92018449]\n",
      " ...\n",
      " [ 1.         -0.45723469  0.46623269 ... -0.20003512  0.12592562\n",
      "   0.25104607]\n",
      " [ 1.         -0.51861356  0.51033223 ... -0.07427231  0.37900884\n",
      "   0.11079427]\n",
      " [ 1.         -0.54273994  0.51807066 ...  0.06601453  0.46063285\n",
      "  -0.0291686 ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_ders_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ad4b45e7-6be5-48fc-958d-f4b2fcfe6c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rajgark/Documents/GitHub/COLSA-PySINDy/Notebooks/PDE_FIND.py:430: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  w_best = np.linalg.lstsq(TrainR, TrainY)[0]\n",
      "/Users/rajgark/Documents/GitHub/COLSA-PySINDy/Notebooks/PDE_FIND.py:575: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if lam != 0: w = np.linalg.lstsq(X.T.dot(X) + lam*np.eye(d),X.T.dot(y))[0]\n",
      "/Users/rajgark/Documents/GitHub/COLSA-PySINDy/Notebooks/PDE_FIND.py:601: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if lam != 0: w[biginds] = np.linalg.lstsq(X[:, biginds].T.dot(X[:, biginds]) + lam*np.eye(len(biginds)),X[:, biginds].T.dot(y))[0]\n",
      "/Users/rajgark/Documents/GitHub/COLSA-PySINDy/Notebooks/PDE_FIND.py:605: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if biginds != []: w[biginds] = np.linalg.lstsq(X[:, biginds],y)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u_t = (-0.468759 +0.000000i)v\n",
      "    + (0.145637 +0.000000i)u\n",
      "    + (0.652594 +0.000000i)v^3\n",
      "    + (0.648310 +0.000000i)u^2v\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "lam = 10**-5\n",
    "d_tol = 1\n",
    "c = pdefind.TrainSTRidge(X_n,utn,lam,d_tol)\n",
    "pdefind.print_pde(c, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a031c1b0-6935-45a9-a380-2832faba4bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 10**-5\n",
    "d_tol = 1\n",
    "c = pdefind.TrainSTRidge(X_n,vtn,lam,d_tol)\n",
    "pdefind.print_pde(c, description, ut = 'v_t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0299a48f-fa84-4e17-9f82-6c3747dd7d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7952857142857153\n",
      "2.3844823552823935\n"
     ]
    }
   ],
   "source": [
    "err = abs(np.array([(0.1-0.094870)*100/0.1,  (0.1-0.094934)*100/0.1,\n",
    "                    (0.1-0.094970)*100/0.1,  (0.1-0.094939)*100/0.1,\n",
    "                    (1-0.944877)*100,        (1-0.946222)*100,\n",
    "                    (1-0.944831)*100,        (1-0.999442)*100,\n",
    "                    (1-0.999758)*100,        (1-0.999674)*100,\n",
    "                    (1-0.999770)*100,        (1-0.946074)*100,\n",
    "                    (1-0.945130)*100,        (1-0.945752)*100]))\n",
    "print(np.mean(err))\n",
    "print(np.std(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a8f86b-8d3f-498e-a62e-4f71a6e0e3d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a558825b-36e5-4916-81a4-2c92c0ab9350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493df20c-a695-4592-b685-7c4633f0d7a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c000b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7792688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_laplacian(u, bdy):\n",
    "    if bdy == 'Periodic':\n",
    "        L = -4*u\n",
    "        L += np.roll(u, (0,-1), (0,1))\n",
    "        L += np.roll(u, (0,+1), (0,1))\n",
    "        L += np.roll(u, (-1,0), (0,1))\n",
    "        L += np.roll(u, (+1,0), (0,1))\n",
    "        return L\n",
    "    elif bdy == 'Dirichlet':\n",
    "        v = np.pad(u, 1, constant_values=0)\n",
    "    elif bdy == 'Neumann':\n",
    "        v = np.pad(u, 1, mode='edge')\n",
    "    L = -4*v\n",
    "    L += np.roll(v, (0,-1), (0,1))\n",
    "    L += np.roll(v, (0,+1), (0,1))\n",
    "    L += np.roll(v, (-1,0), (0,1))\n",
    "    L += np.roll(v, (+1,0), (0,1))\n",
    "    L = L[1:-1,1:-1]\n",
    "    return L\n",
    "\n",
    "def leapfrog(u0, um, cfl, bdy):\n",
    "    up = 2*u0 - um + cfl**2*discrete_laplacian(u0, bdy)\n",
    "    return up, u0\n",
    "\n",
    "def define_initial_condition(f, g, dt, bdy):\n",
    "    u0 = f + 0.5*cfl**2*discrete_laplacian(f, bdy) + dt*g\n",
    "    return u0, f\n",
    "\n",
    "def update_solution(f, g, cfl, dt, bdy, Nframes, Nskip):\n",
    "    n = 0\n",
    "    u0, um = define_initial_condition(f, g, dt, bdy)\n",
    "    while n<Nframes:\n",
    "        n += 1\n",
    "        for k in range(Nskip):\n",
    "            u0, um = leapfrog(u0, um, cfl, bdy)\n",
    "        yield u0\n",
    "\n",
    "def update_graph(u, ls, imu):\n",
    "    imu.set_array(ls.hillshade(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe64807",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# model parameter\n",
    "c = 1       # speed constant\n",
    "L = 100      # domain length\n",
    "\n",
    "# numerical parameters\n",
    "N = 800    # grid size\n",
    "\n",
    "# define a function that simulates a raindrop\n",
    "def pebble(X, Y, width, positionX, positionY):\n",
    "    r = width*np.sqrt((X-positionX)**2 + (Y-positionY)**2)\n",
    "    u = np.random.uniform(-1., 1., 1)*np.cos(1.9*r)/np.cosh(r)\n",
    "    return u\n",
    "\n",
    "x = np.linspace(0, L, N)\n",
    "X, Y = np.meshgrid(x, x)\n",
    "\n",
    "# initial displacement consists of three separate raindrops \n",
    "f =  pebble(X, Y, 3.5, 0.35*L, 0.5*L)\n",
    "f += pebble(X, Y, 3, 0.6*L, 0.6*L)\n",
    "f += pebble(X, Y, 4, 0.7*L, 0.2*L)\n",
    "\n",
    "# initial velocity is zero\n",
    "g = np.zeros((N,N))\n",
    "\n",
    "# animation parameters\n",
    "Nsteps = 400\n",
    "Nskip = 10\n",
    "\n",
    "# set time step to satisfy leapfrog stability criterion (cfl < 1/sqrt(2) ~ 0.7)\n",
    "cfl = 0.6\n",
    "dx = L/N\n",
    "dt = cfl * dx / c\n",
    "#dt = 0.00001\n",
    "\n",
    "# compute and animate solution\n",
    "Nframes = int(Nsteps/Nskip)\n",
    "extent = [0, L, 0, L]\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "ls = LightSource(azdeg=220, altdeg=70)\n",
    "imu = ax.imshow(ls.hillshade(f), cmap='terrain', animated=True, extent=extent, origin='lower')\n",
    "ani = animate.FuncAnimation(fig, update_graph,\n",
    "                              update_solution(f, g, cfl, dt, 'Neumann', Nframes, Nskip),\n",
    "                              fargs=(ls, imu), repeat=False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82164463",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df04610",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ut, R, rhs_des = pdefind.build_linear_system(f, dt, dx, D=3, P=3, time_diff = 'FD', space_diff = 'FD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a32f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "['1']+rhs_des[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcf3509",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = pdefind.TrainSTRidge(R,Ut,10**-5,5)\n",
    "print(\"PDE derived using STRidge\")\n",
    "pdefind.print_pde(w, rhs_des)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
