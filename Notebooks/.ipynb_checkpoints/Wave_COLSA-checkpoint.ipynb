{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e5fac55",
   "metadata": {},
   "source": [
    "# PySINDy Exploration & Applications\n",
    "\n",
    "## COLSA Corporation \n",
    "\n",
    "### Raj Garkhedkar, DACS Lab Summer 2021 Intern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1d7543",
   "metadata": {},
   "source": [
    "## Waves\n",
    "\n",
    "\n",
    "-- -- -- -- -- --\n",
    "###### Links \n",
    "\n",
    "[Convection Diffusion Equation ](https://www.sciencedirect.com/topics/physics-and-astronomy/convection-diffusion-equation)\n",
    "\n",
    "[Nonlinear Advection Diffusion Equation 2nd Order FD Scheme](https://math.mit.edu/classes/18.086/2014/reports/ZachCordero.pdf)\n",
    "\n",
    "[All Analytic Sol's Convection Diffusion](https://www.nature.com/articles/s41598-020-63982-w)\n",
    "\n",
    "[Reflected Sound Discriminator](https://github.com/diabelmehdi/Machine_Learning_project/blob/master/realiz/Documentation/machine%20learning%20report_DIAB_ELMEHDI.pdf)\n",
    "\n",
    "[Deep Learning Machine Solves the Cocktail Party Problem](https://www.technologyreview.com/2015/04/29/168316/deep-learning-machine-solves-the-cocktail-party-problem/)\n",
    "\n",
    "[Deep Karaoke: Extracting Vocals](https://arxiv.org/abs/1504.04658)\n",
    "\n",
    "[Diff Eq's in Physics](https://olewitthansen.dk/Physics/differential_equations_of_physics.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86f8770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.colors as colors\n",
    "import ipywidgets\n",
    "import itertools\n",
    "import scipy.io as sio\n",
    "import PDE_FIND as pdefind\n",
    "import pandas as pd\n",
    "import sys\n",
    "import gdown\n",
    "import tensorflow as tf\n",
    "from matplotlib.colors import LightSource\n",
    "from matplotlib import interactive, rc\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "# from IPython.display import HTML\n",
    "# plt.rcParams[\"animation.html\"] = \"jshtml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d66744",
   "metadata": {},
   "source": [
    "## Advection - Diffusion PDE\n",
    "-- -- --\n",
    "The equation: \n",
    "$$u_t + a u_x = \\epsilon u_{xx}$$\n",
    "\n",
    "This might be the density or concentration of some substance and how the energy, particles, or some other physical quantity is transferred in a physical system through two processes: _diffusion and advection_. The subscripts denote partial differentiation; e.g. $u_t$ is the partial derivative of $u$ with respect to $t$. The coefficients $a$ and $\\epsilon$ are constants that determine the strength of the advective and diffusive effects. We wish to find $u(x,t)$. Depending on context, the same equation can be called the advection–diffusion equation, drift–diffusion equation, or scalar transport equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7cf84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "2*np.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8844baa",
   "metadata": {},
   "source": [
    "### Exact Solution by Fourier Analysis\n",
    "\n",
    "Solved on a periodic domain $[-\\pi,\\pi]$, with some initial data: $$u(x,0) = u_0(x)$$\n",
    "\n",
    "Under the assumption that the solution is composed of a single Fourier mode with wavenumber $\\xi$ and time-dependent amplitude $\\hat{u}$:\n",
    "$$u(x,t; \\xi) = \\hat{u}(t) e^{i\\xi x}$$\n",
    "\n",
    "Then a simple ordinary differential equation for $\\hat{u}$:\n",
    "$$\\hat{u}'(t; \\xi) + i\\xi a \\hat{u} = -\\xi^2 \\epsilon \\hat{u}$$\n",
    "\n",
    "The scalar ODE can be solved exactly:\n",
    "$$\\hat{u}(t; \\xi) = e^{(-i \\xi a - \\epsilon \\xi^2)t} \\hat{u}(0)$$\n",
    "\n",
    "Every solution of our advection-diffusion equation can be written as a linear combination (a superposition) of simple solutions of the form above, with different wavenumbers $\\xi$. The general solution can be obtained by first, taking a Fourier transform of the initial data:\n",
    "$$\\hat{u}(t=0;\\xi) = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^\\infty u_0(x) e^{-i\\xi x}dx$$\n",
    "\n",
    "Then each mode evolves according to the solution of the ODE above:\n",
    "$$\\hat{u}'(t; \\xi) = e^{(-i \\xi a - \\epsilon \\xi^2)t} \\hat{u}(0;\\xi)$$\n",
    "\n",
    "A solution is constructed again by taking the inverse Fourier transform, meaning summing up all the Fourier modes:\n",
    "$$u(x,t) = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^\\infty \\hat{u}_0(x) e^{i\\xi x}d\\xi$$\n",
    "\n",
    "Discretizing the integral with finite points in space & time below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2616f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 64                          # Number of grid points in space\n",
    "L = 2 * np.pi                   # Width of spatial domain\n",
    "x = np.arange(-m/2,m/2)*(L/m)   # Grid points \n",
    "dx = x[1]-x[0]                  # Grid spacing\n",
    "\n",
    "tmax = 8.0   # Final time\n",
    "N = 50       # # of grid points in time\n",
    "dt = tmax/N   # interval between output times\n",
    "\n",
    "xi = np.fft.fftfreq(m)*m*2*np.pi/L \n",
    "\n",
    "# Initial data\n",
    "u = np.sin(2*x)**2 * (x<-L/4)\n",
    "uhat0 = np.fft.fft(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd147b7",
   "metadata": {},
   "source": [
    "`xi = np.fft.fftfreq(m)*m*2*np.pi/L` order of numpy's FFT frequencies\n",
    "\n",
    "The functions $u, \\hat{u}$ discussed above are replaced by finite-dimensional vectors. These vectors are related through the discrete version of the Fourier transform (DFT). \n",
    "\n",
    "Initial conditions:\n",
    "\n",
    "$$u_0(x) = \\begin{cases} \\sin^2(2x) & -\\pi \\le x < -\\pi/2 \\\\ 0 & x>-\\pi/2 \\end{cases}$$\n",
    "\n",
    "`diffusion_coef` is epsilon, the diffusion coefficient\n",
    "\n",
    "`advection_coef` is the advection coefficient\n",
    "\n",
    "Similarly, change `tmax` in the above cell to increase or decrease the time boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1bfdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_coef = 0.05    # Diffusion coefficient\n",
    "advection_coef = 1       # Advection coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61acd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution list\n",
    "frames = [u.copy()]\n",
    "\n",
    "# Solution to problem\n",
    "for n in range(1,N+1):\n",
    "    t = n*dt\n",
    "    uhat = np.exp(-(1.j*xi*advection_coef + diffusion_coef*xi**2)*t) * uhat0\n",
    "    u = np.real(np.fft.ifft(uhat))\n",
    "    frames.append(u.copy())\n",
    "\n",
    "# Initialize plotting\n",
    "fig = plt.figure(figsize=(9,4)); axes = fig.add_subplot(111)\n",
    "line, = axes.plot([],[],lw=3)\n",
    "axes.set_xlim((x[0],x[-1])); axes.set_ylim((0.,1.))\n",
    "\n",
    "def plot_frame(i):\n",
    "    #fig = plt.figure()\n",
    "    #plt.plot(x,frames[i])\n",
    "    line.set_data(x,frames[i])\n",
    "    axes.set_title('t='+str(i*dt))\n",
    "    fig.canvas.draw()\n",
    "    return fig\n",
    "\n",
    "anim = animation.FuncAnimation(fig, plot_frame,\n",
    "                                   frames=len(frames),\n",
    "                                   interval=350,\n",
    "                                   repeat=False)\n",
    "\n",
    "# def ani(): \n",
    "#     animate.FuncAnimation(fig, plot_frame,\n",
    "#                                    frames=len(frames),\n",
    "#                                    interval=350,\n",
    "#                                    repeat=True)\n",
    "plt.tight_layout()\n",
    "#anim.save('/Users/rajgark/Documents/GitHub/COLSA-PySINDy/WavesData/anim.mp4')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67330c19",
   "metadata": {},
   "source": [
    "The first approximation was to take the initial data and approximate it by just the first terms in its Fourier series. The vector $\\hat{u}$ contains the first 64 Fourier modes (because 64 points are in the spatial grid vector $x$).\n",
    "\n",
    "The time evolution of the solution is exact for the initial data vector, since it uses the exact solution formula for the ODE above.\n",
    "\n",
    "### For Generality...\n",
    "This methodology can be used to solve any linear evolution PDE (including systems of PDEs, like the following scalar PDEs):\n",
    "\n",
    "$$u_t = \\sum_{j=0}^n \\alpha_j \\frac{\\partial^j u}{\\partial x^j}.$$\n",
    "Taking Fourier transform or applying our ansatz:\n",
    "$$u(x,t; \\xi) = \\hat{u}(t) e^{i\\xi x},$$\n",
    "The following linear ODE is obtained:\n",
    "$$\\hat{u}'(t) = \\left(\\sum_{j=0}^n \\alpha_j (i\\xi)^j\\right) \\hat{u}(t) = p(\\xi)\\hat{u}(t)$$\n",
    "With solution:\n",
    "$$\\hat{u}(t) = e^{p(\\xi)t}\\hat{u}(0)$$\n",
    "so that\n",
    "$$u(x,t; \\xi) = e^{i\\xi x + p(\\xi)t} \\hat{u}(0).$$\n",
    "Here $p(\\xi)$ is a polynomial with coefficients $i^j \\alpha_j$.\n",
    "\n",
    "The odd-derivative terms correspond to imaginary terms in $p(\\xi)$, which (in the exponential) lead to changes in the phase of the solution, while even-derivative terms correspond to real terms in $p(\\xi)$, which lead to changes in the amplitude of the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9346560",
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(a) for a in frames][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce86b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "framearray = np.asarray(frames)\n",
    "framearray.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657af5c6-7304-4670-b8b3-02dac74368a6",
   "metadata": {},
   "source": [
    "So there are 51 arrays with 64 discretized points of the wave per array, this forms the dataset showing the evolution of the waves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8b2e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ut,R,rhs_des = pdefind.build_linear_system(framearray, dt, dx, D=2, P=3, time_diff = 'FD', deg_x = 4, width_x = 5, width_t = 6)\n",
    "w = pdefind.TrainSTRidge(R, Ut, 10**-2, 10, normalize = 2)\n",
    "\n",
    "print(\"Candidate functions for PDE\")\n",
    "for func in ['1'] + rhs_des[1:]: print(func)\n",
    "print('-- -- -- --')\n",
    "print('Derived PDE:')\n",
    "pdefind.print_pde(w, rhs_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c74554-c7e5-45ba-b717-0a9132ff34c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dx)\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8139d06-6980-4b10-9871-a672fd302945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bb651ce",
   "metadata": {},
   "source": [
    "## PDE-FIND Implementation\n",
    "Below is the PDE-FIND replication exercise for their advection diffusion coefficient discovery method. \n",
    "A time series of length $10^6$ is generated with $x_{n+1} \\sim \\mathcal{N}(x_n, dt)$. From this we approximate the distribution function of the future potision of the trajectory and fit to a PDE. In theory, we expect $f_t = 0.5f_{xx}$. The algorithm achieves the correct PDE with parameter error $\\sim 10^{-3}$.\n",
    "\n",
    "A second time series is used to try to identify the advection diffusion equation. This time, $x_{n+1} \\sim \\mathcal{N}(x_n + c dt, dt)$. We expect the distribution function to follow $f_t = 0.5f_{xx} - c f_x$. Trying a few different sparsity promoting methods yields different results, with greedy algorithm being the only one that works.\n",
    "\n",
    "### Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d5b240",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (14,10))\n",
    "'''\n",
    "Data Generation\n",
    "'''\n",
    "length = 10**6\n",
    "dt = 0.01\n",
    "np.random.seed(0)\n",
    "pos = np.cumsum(np.sqrt(dt)*np.random.randn(length))\n",
    "\n",
    "P = {}\n",
    "M = 0\n",
    "\n",
    "m = 5\n",
    "n = 300\n",
    "\n",
    "for i in range(m):\n",
    "    P[i] = []\n",
    "    \n",
    "for i in range(len(pos)-m):\n",
    "    \n",
    "    # center\n",
    "    y = pos[i+1:i+m+1] - pos[i]\n",
    "    M = max([M, max(abs(y))])\n",
    "    \n",
    "    # add to distribution\n",
    "    for j in range(m):\n",
    "        P[j].append(y[j])\n",
    "    \n",
    "bins = np.linspace(-M,M,n+1)\n",
    "x = np.linspace(M*(1/n-1),M*(1-1/n),n)\n",
    "dx = x[2]-x[1]\n",
    "T = np.linspace(0,dt*(m-1),m)\n",
    "U = np.zeros((n,m))\n",
    "for i in range(m):\n",
    "    U[:,i] = plt.hist(P[i],bins,label=r'$t = $' + str(i*dt+dt))[0]/float(dx*(len(pos)-m))\n",
    "    \n",
    "plt.xlabel('Location')\n",
    "plt.ylabel(r'$f(x,t)$')\n",
    "plt.title(r'Histograms for $f(x,t)$')\n",
    "#xticks(fontsize = tickfontsize); yticks(fontsize = tickfontsize)\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebff550",
   "metadata": {},
   "outputs": [],
   "source": [
    "U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97c977a-cc45-4b10-9c64-4505736a13b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ut,R,rhs_des = pdefind.build_linear_system(U, dt, dx, D=4, P=5, time_diff = 'FD', deg_x = 4, width_x = 30, width_t = 1)\n",
    "w = pdefind.TrainSTRidge(R, Ut, 10**-2, 10, normalize = 2)\n",
    "\n",
    "print(\"Candidate functions for PDE\")\n",
    "for func in ['1'] + rhs_des[1:]: print(func)\n",
    "\n",
    "print(\"\\nPDE derived from data:\")\n",
    "pdefind.print_pde(w, rhs_des)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a858348f",
   "metadata": {},
   "source": [
    "### Advection - Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edc7997",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (14,10))\n",
    "''' \n",
    "Data Generation\n",
    "'''\n",
    "length = 10**6\n",
    "\n",
    "dt = 0.099    # Diffusion Term\n",
    "c = 5         # Advection Term\n",
    "np.random.seed(0)\n",
    "pos = np.cumsum(np.sqrt(dt)*np.random.randn(length)) + c*dt*np.arange(length)\n",
    "\n",
    "P = {}\n",
    "M = 0\n",
    "\n",
    "m = 5\n",
    "n = 300\n",
    "\n",
    "for i in range(m):\n",
    "    P[i] = []\n",
    "    \n",
    "for i in range(len(pos)-m):\n",
    "    \n",
    "    # center\n",
    "    y = pos[i+1:i+m+1] - pos[i]\n",
    "    M = max([M, max(abs(y))])\n",
    "    \n",
    "    # add to distribution\n",
    "    for j in range(m):\n",
    "        P[j].append(y[j])\n",
    "    \n",
    "bins = np.linspace(-M,M,n+1)\n",
    "x = np.linspace(M*(1/n-1),M*(1-1/n),n)\n",
    "dx = x[2]-x[1]\n",
    "T =  np.linspace(0,dt*(m-1),m)\n",
    "U = np.zeros((n,m))\n",
    "for i in range(m):\n",
    "    U[:,i] = plt.hist(P[i],bins,label=r'$t = $' + str(i*dt+dt))[0]/float(dx*(len(pos)-m))\n",
    "    \n",
    "    \n",
    "plt.xlabel('Location')\n",
    "plt.ylabel(r'$f(x,t)$')\n",
    "plt.title(r'Histograms for $f(x,t)$')\n",
    "#plt.xticks(fontsize = tickfontsize); yticks(fontsize = tickfontsize)\n",
    "plt.legend(loc = 'upper right', fontsize = 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f64579a-149f-44b2-a17b-1c39abb1a6ed",
   "metadata": {},
   "source": [
    "Now try to identify the dynamics. This is an example of how different sparsity promoting regression methods can behave differently. Here the STRidge algorithm works only when the data is not normalized. The greedy algorithm seems to be fairly robust to small changes, and Lasso works with some tuning (maybe only because we know the right answer). Normally STRidge with $L^2$ normalization outperforms all the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732cc446-1deb-49eb-b380-5d4f123c36d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ut,R,rhs_des = pdefind.build_linear_system(U, dt, dx, D=4, P=5, time_diff = 'FD', deg_x = 4, width_x = 30, width_t = 1)\n",
    "\n",
    "print(\"Candidate functions for PDE\")\n",
    "for func in ['1'] + rhs_des[1:]: print(func)\n",
    "print('-- -- -- -- -- -- -- --')\n",
    "print(\"\\nPDE derived with STRidge and L^2 normalization (Somewhat Correct PDE)\")\n",
    "w = pdefind.TrainSTRidge(R, Ut, 1, 4, normalize = 2)\n",
    "pdefind.print_pde(w, rhs_des)\n",
    "\n",
    "print(\"PDE derived with STRidge without normalization\")\n",
    "w = pdefind.TrainSTRidge(R, Ut, 1, 0.01, normalize = 0)\n",
    "pdefind.print_pde(w, rhs_des)\n",
    "\n",
    "print(\"PDE derived with greedy algorithm (Correct PDE!)\")\n",
    "w = pdefind.FoBaGreedy(R, Ut,10)\n",
    "pdefind.print_pde(w, rhs_des)\n",
    "\n",
    "print(\"PDE derived with LASSO algorithm\")\n",
    "w = pdefind.Lasso(R, Ut,10)\n",
    "pdefind.print_pde(w, rhs_des)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7312e873-f0ce-4fe2-a687-f7dec5011db4",
   "metadata": {},
   "source": [
    "### Reaction Diffusion System, PDE-FIND Implementation\n",
    "\n",
    "PDE-FIND for a $\\lambda - \\omega$ reaction diffusion system exhibiting sprial waves on a periodic domain. We derive PDE's for each of two quantities, having dependancies on each other; $u$ and $v$.\n",
    "\n",
    "$$\\begin{align*} u_t &= 0.1\\nabla^2 u + \\lambda(A)u - \\omega(A)v\\\\ v_t &= 0.1\\nabla^2 v + \\omega(A)u + \\lambda(A)v\\\\ A^2 &= u^2 + v^2,\\, \\omega(A) = -\\beta A^2, \\lambda(A) = 1-A^2 \\end{align*}$$\n",
    "\n",
    "Unlike other implmentations, we allow for $u_t$ to be dependent on derivatives of $v$, even though this is not the case in the true PDE. The sparse regression is still able to derive the correct PDE.\n",
    "-- -- -- -- \n",
    "##### Notes\n",
    "\n",
    "Their dataset wasn't generated, was just a MATLAB script & function. I generated data from their MATLAB code, converted it to a .csv below & carried out the rest of the notebook, dataset in the repo (as a .csv - original MATLAB scripts in it as well but they take forever to compute & the .mat file containing the data is too big for MATLAB and Jupyter to handle effectively. \n",
    "\n",
    "I can't upload the original `reacdiffdataset.mat` because the filesize is too large for GitHub and GitHub LFS requires migrating the entire working directory & a whole bunch of unnecessary stuff - I instead converted it all into a csv for ease of use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f9eba09-c435-49c9-9ff2-d69e1f655390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep hashed out stuff hashed out\n",
    "\n",
    "data = sio.loadmat('/Users/rajgark/Desktop/Colsa/reacdiffdataset.mat')\n",
    "t = np.array(data['t'][:,0])\n",
    "x = np.array(data['x'][0,:])\n",
    "y = np.array(data['y'][0,:])\n",
    "U = np.array(data['u'])\n",
    "V = np.array(data['v'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a7709cf-763c-4c0a-8549-5db40f2bb1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tf.convert_to_tensor(x, allow_pickle=False)\\ntf.convert_to_tensor(y, allow_pickle=False)\\ntf.convert_to_tensor(U, allow_pickle=False)\\ntf.convert_to_tensor(V, allow_pickle=False)'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.io.write_file(\"/Users/rajgark/Documents/GitHub/COLSA-PySINDy/WavesData/nparrays/t_tens\", tf.io.serialize_tensor(tf.convert_to_tensor(t)))\n",
    "tf.io.write_file(\"/Users/rajgark/Documents/GitHub/COLSA-PySINDy/WavesData/nparrays/x_tens\", tf.io.serialize_tensor(tf.convert_to_tensor(x)))\n",
    "tf.io.write_file(\"/Users/rajgark/Documents/GitHub/COLSA-PySINDy/WavesData/nparrays/y_tens\", tf.io.serialize_tensor(tf.convert_to_tensor(y)))\n",
    "tf.io.write_file(\"/Users/rajgark/Documents/GitHub/COLSA-PySINDy/WavesData/nparrays/U_tens\", tf.io.serialize_tensor(tf.convert_to_tensor(U)))\n",
    "tf.io.write_file(\"/Users/rajgark/Documents/GitHub/COLSA-PySINDy/WavesData/nparrays/V_tens\", tf.io.serialize_tensor(tf.convert_to_tensor(V)))\n",
    "\n",
    "#tf.io.write_file(tf.io.serialize_tensor(tf.convert_to_tensor(t)), \"/Users/rajgark/Documents/GitHub/COLSA-PySINDy/WavesData/nparrays/t_tens\")\n",
    "\"\"\"tf.convert_to_tensor(x, allow_pickle=False)\n",
    "tf.convert_to_tensor(y, allow_pickle=False)\n",
    "tf.convert_to_tensor(U, allow_pickle=False)\n",
    "tf.convert_to_tensor(V, allow_pickle=False)\"\"\"\n",
    "\n",
    "# reacdiffdict = {\n",
    "#     't': t,\n",
    "#     'x': x,\n",
    "#     'y': y,\n",
    "#     'U': U,\n",
    "#     'V': V\n",
    "# }\n",
    "\n",
    "# with open('reacdiffcsv.csv', 'w') as f:\n",
    "#     for key in reacdiffdict.keys():\n",
    "#         f.write(\"%s,%s\\n\"%(key,reacdiffdict[key]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2ccb0a9-fbb5-4d36-b1b7-3a1effc96d98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d9b9e9a-bf43-4f31-ae4c-69a0f8b846c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/drive/folders/1E3esK-Ct-aAiOFacaZ9x4v_B-1OvNi7c?usp=sharing\n",
      "To: /Users/rajgark/Documents/GitHub/COLSA-PySINDy/Notebooks/t_tens\n",
      "236kB [00:00, 1.55MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/drive/folders/1E3esK-Ct-aAiOFacaZ9x4v_B-1OvNi7c?usp=sharing\n",
      "To: /Users/rajgark/Documents/GitHub/COLSA-PySINDy/Notebooks/x_tens\n",
      "236kB [00:00, 1.29MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/drive/folders/1E3esK-Ct-aAiOFacaZ9x4v_B-1OvNi7c?usp=sharing\n",
      "To: /Users/rajgark/Documents/GitHub/COLSA-PySINDy/Notebooks/y_tens\n",
      "236kB [00:00, 1.54MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/drive/folders/1E3esK-Ct-aAiOFacaZ9x4v_B-1OvNi7c?usp=sharing\n",
      "To: /Users/rajgark/Documents/GitHub/COLSA-PySINDy/Notebooks/U_tens\n",
      "236kB [00:00, 1.54MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/drive/folders/1E3esK-Ct-aAiOFacaZ9x4v_B-1OvNi7c?usp=sharing\n",
      "To: /Users/rajgark/Documents/GitHub/COLSA-PySINDy/Notebooks/V_tens\n",
      "236kB [00:00, 1.09MB/s]\n"
     ]
    }
   ],
   "source": [
    "#gdown_url = 'https://drive.google.com/drive/folders/1E3esK-Ct-aAiOFacaZ9x4v_B-1OvNi7c?usp=sharing'\n",
    "gdown_url = 'https://drive.google.com/drive/folders/1E3esK-Ct-aAiOFacaZ9x4v_B-1OvNi7c?usp=sharing'\n",
    "t_url = 't_tens'\n",
    "x_url = 'x_tens'\n",
    "y_url = 'y_tens'\n",
    "U_url = 'U_tens'\n",
    "V_url = 'V_tens'\n",
    "\n",
    "tfile = gdown.download(gdown_url, t_url, quiet=False)\n",
    "xfile = gdown.download(gdown_url, x_url, quiet=False)\n",
    "yfile = gdown.download(gdown_url, y_url, quiet=False)\n",
    "ufile = gdown.download(gdown_url, U_url, quiet=False)\n",
    "vfile = gdown.download(gdown_url, V_url, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b39071cd-1607-4f29-b2cd-76d6c298ef73",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot load file containing pickled data when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-c52807fd3bf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                 raise ValueError(\"Cannot load file containing pickled data \"\n\u001b[0m\u001b[1;32m    446\u001b[0m                                  \"when allow_pickle=False\")\n\u001b[1;32m    447\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot load file containing pickled data when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "m = np.load(tfile, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27ad59b-81e2-46ce-9ed3-c43e227e44e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e796cf83-59ce-4a04-818d-a9e8a73256c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4462e919-af0a-4014-98ef-242302d084e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8564b3-3582-44e1-a6d9-d33e01d82884",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.set_printoptions(threshold=sys.maxsize)\n",
    "np.set_printoptions(threshold=1)\n",
    "print('t shape: ',t.shape)\n",
    "print('x shape: ',x.shape)\n",
    "print('y shape: ',y.shape)\n",
    "print('U shape: ',U.shape)\n",
    "print('V shape: ',V.shape)\n",
    "print('-- -- -- -- -- -- -- -- --')\n",
    "print('t type: ',type(t))\n",
    "print('x type: ',type(x))\n",
    "print('y type: ',type(y))\n",
    "print('U type: ',type(U))\n",
    "print('V type: ',type(V))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c28560c-6d44-4667-9451-adb26479c6f8",
   "metadata": {},
   "source": [
    "`U` and `V` tensors are massive: `(512, 512, 201)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4edcf7-f5ed-4104-b988-5aeba375ed46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8aaccd44-8bc7-4d27-b18f-5bfcd59c0206",
   "metadata": {},
   "source": [
    "Ensuring everything is imported properly with appropriate variable types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4fa76c-0ed1-47a9-9c76-cd6c5c7f56e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76c3f2b-6045-4e6b-a60c-5512cad245e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e591deff-c894-4ed9-8584-479ac9272438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cb1a1b-3628-4b8c-ae6f-1212e1c466d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8285041-18d8-47af-9fd5-4543a80d31da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe604b75-880f-4cd9-bdba-3a9883444c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b558e83-a44e-4da2-997e-90970528b962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c36826-18a7-4a90-a9d1-728d3d6fc88e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25dfd62-8b3a-461f-90e5-d31ee160081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = '/Users/rajgark/Documents/GitHub/COLSA-PySINDy/WavesData/clean_reacdiff.csv'\n",
    "test = pd.read_csv(csv)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380536c8-8a23-46cb-9f0c-b8a9e888cff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576e8b13-db79-4191-b05d-60d49b6011cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5c19d8-c559-4763-be21-801a460ea697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b7f395-0ae8-46ff-9806-3ce634e5b07f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc743ca-bf1c-4bae-b76a-5fc2436c8f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b45e7-6be5-48fc-958d-f4b2fcfe6c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a031c1b0-6935-45a9-a380-2832faba4bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0299a48f-fa84-4e17-9f82-6c3747dd7d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a8f86b-8d3f-498e-a62e-4f71a6e0e3d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a558825b-36e5-4916-81a4-2c92c0ab9350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493df20c-a695-4592-b685-7c4633f0d7a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c000b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7792688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_laplacian(u, bdy):\n",
    "    if bdy == 'Periodic':\n",
    "        L = -4*u\n",
    "        L += np.roll(u, (0,-1), (0,1))\n",
    "        L += np.roll(u, (0,+1), (0,1))\n",
    "        L += np.roll(u, (-1,0), (0,1))\n",
    "        L += np.roll(u, (+1,0), (0,1))\n",
    "        return L\n",
    "    elif bdy == 'Dirichlet':\n",
    "        v = np.pad(u, 1, constant_values=0)\n",
    "    elif bdy == 'Neumann':\n",
    "        v = np.pad(u, 1, mode='edge')\n",
    "    L = -4*v\n",
    "    L += np.roll(v, (0,-1), (0,1))\n",
    "    L += np.roll(v, (0,+1), (0,1))\n",
    "    L += np.roll(v, (-1,0), (0,1))\n",
    "    L += np.roll(v, (+1,0), (0,1))\n",
    "    L = L[1:-1,1:-1]\n",
    "    return L\n",
    "\n",
    "def leapfrog(u0, um, cfl, bdy):\n",
    "    up = 2*u0 - um + cfl**2*discrete_laplacian(u0, bdy)\n",
    "    return up, u0\n",
    "\n",
    "def define_initial_condition(f, g, dt, bdy):\n",
    "    u0 = f + 0.5*cfl**2*discrete_laplacian(f, bdy) + dt*g\n",
    "    return u0, f\n",
    "\n",
    "def update_solution(f, g, cfl, dt, bdy, Nframes, Nskip):\n",
    "    n = 0\n",
    "    u0, um = define_initial_condition(f, g, dt, bdy)\n",
    "    while n<Nframes:\n",
    "        n += 1\n",
    "        for k in range(Nskip):\n",
    "            u0, um = leapfrog(u0, um, cfl, bdy)\n",
    "        yield u0\n",
    "\n",
    "def update_graph(u, ls, imu):\n",
    "    imu.set_array(ls.hillshade(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe64807",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed()\n",
    "\n",
    "# model parameter\n",
    "c = 1       # speed constant\n",
    "L = 100      # domain length\n",
    "\n",
    "# numerical parameters\n",
    "N = 800    # grid size\n",
    "\n",
    "# define a function that simulates a raindrop\n",
    "def pebble(X, Y, width, positionX, positionY):\n",
    "    r = width*np.sqrt((X-positionX)**2 + (Y-positionY)**2)\n",
    "    u = np.random.uniform(-1., 1., 1)*np.cos(1.9*r)/np.cosh(r)\n",
    "    return u\n",
    "\n",
    "x = np.linspace(0, L, N)\n",
    "X, Y = np.meshgrid(x, x)\n",
    "\n",
    "# initial displacement consists of three separate raindrops \n",
    "f =  pebble(X, Y, 3.5, 0.35*L, 0.5*L)\n",
    "f += pebble(X, Y, 3, 0.6*L, 0.6*L)\n",
    "f += pebble(X, Y, 4, 0.7*L, 0.2*L)\n",
    "\n",
    "# initial velocity is zero\n",
    "g = np.zeros((N,N))\n",
    "\n",
    "# animation parameters\n",
    "Nsteps = 400\n",
    "Nskip = 10\n",
    "\n",
    "# set time step to satisfy leapfrog stability criterion (cfl < 1/sqrt(2) ~ 0.7)\n",
    "cfl = 0.6\n",
    "dx = L/N\n",
    "dt = cfl * dx / c\n",
    "#dt = 0.00001\n",
    "\n",
    "# compute and animate solution\n",
    "Nframes = int(Nsteps/Nskip)\n",
    "extent = [0, L, 0, L]\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "ls = LightSource(azdeg=220, altdeg=70)\n",
    "imu = ax.imshow(ls.hillshade(f), cmap='terrain', animated=True, extent=extent, origin='lower')\n",
    "ani = animate.FuncAnimation(fig, update_graph,\n",
    "                              update_solution(f, g, cfl, dt, 'Neumann', Nframes, Nskip),\n",
    "                              fargs=(ls, imu), repeat=False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82164463",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df04610",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ut, R, rhs_des = pdefind.build_linear_system(f, dt, dx, D=3, P=3, time_diff = 'FD', space_diff = 'FD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a32f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "['1']+rhs_des[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcf3509",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = pdefind.TrainSTRidge(R,Ut,10**-5,5)\n",
    "print(\"PDE derived using STRidge\")\n",
    "pdefind.print_pde(w, rhs_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da793a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
